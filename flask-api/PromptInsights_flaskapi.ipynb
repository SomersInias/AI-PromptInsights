{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFQT_qLLJwUI",
        "outputId": "b22967c7-9eff-4ac5-ae49-06022009a67c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SomersInias/AI-PromptInsights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgfRYLVlJUcf",
        "outputId": "f417c690-0a3c-4710-dd8c-45123be7bc4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI-PromptInsights'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 17 (delta 3), pack-reused 11 (from 1)\u001b[K\n",
            "Receiving objects: 100% (33/33), 157.21 MiB | 12.27 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "Updating files: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/AI-PromptInsights/data/RandomUsers_prompts.zip -d /content/extracted_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwumw3_hJbL4",
        "outputId": "04ee65b3-4c90-41f5-f83f-8e36dac446a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/AI-PromptInsights/data/RandomUsers_prompts.zip\n",
            "  inflating: /content/extracted_data/RandomUsers_prompts.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install flask pyngrok\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "import pandas as pd\n",
        "from flask import Flask, request, jsonify, Response\n",
        "from pyngrok import ngrok\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import spacy\n",
        "from io import BytesIO\n",
        "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
        "\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 150_000_000  # Increase as needed\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/extracted_data/RandomUsers_prompts.csv\")\n",
        "\n",
        "\n",
        "# Replace ngrok_auth_token with your actual authtoken from the ngrok dashboard\n",
        "\n",
        "# Read the ngrok auth token from the txt file\n",
        "with open('/content/drive/MyDrive/ngrok_token.txt', 'r') as file:\n",
        "    ngrok_auth_token = file.read().strip()\n",
        "\n",
        "# Authenticate ngrok with the token read from the file\n",
        "!ngrok config add-authtoken {ngrok_auth_token}\n",
        "\n",
        "# Flask app setup\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Analysis function (from your code)\n",
        "def analyze_user_prompts(user_id, df):\n",
        "    user_prompts = df[df['userId'] == user_id]['prompt'].dropna()\n",
        "    all_prompts = \" \".join(user_prompts)\n",
        "    doc = nlp(all_prompts)\n",
        "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and len(token.text) > 2]\n",
        "    word_freq = Counter(tokens)\n",
        "    return word_freq\n",
        "\n",
        "# Plot function (from your code)\n",
        "def plot_horizontal_word_frequencies(sorted_word_freq, top_n=100):\n",
        "    words, frequencies = zip(*sorted_word_freq[:top_n])\n",
        "    plt.figure(figsize=(12, 16))\n",
        "    plt.barh(words, frequencies, color='skyblue')\n",
        "    plt.xlabel('Frequency', fontsize=14)\n",
        "    plt.ylabel('Words', fontsize=14)\n",
        "    plt.title(f'Top {top_n} Word Frequencies', fontsize=16)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    buffer = BytesIO()\n",
        "    plt.savefig(buffer, format='png')\n",
        "    plt.close()\n",
        "    buffer.seek(0)\n",
        "    return buffer\n",
        "\n",
        "# WordCloud function (from your code)\n",
        "def generate_word_cloud(sorted_word_freq):\n",
        "    word_freq_dict = dict(sorted_word_freq)\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate_from_frequencies(word_freq_dict)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    buffer = BytesIO()\n",
        "    plt.savefig(buffer, format='png')\n",
        "    plt.close()\n",
        "    buffer.seek(0)\n",
        "    return buffer\n",
        "\n",
        "# API route for generating word frequency plot (PNG)\n",
        "@app.route('/word_frequencies', methods=['GET'])\n",
        "def word_frequencies():\n",
        "    user_id = request.args.get('user_id', type=int)\n",
        "    x = request.args.get('x', default=20, type=int)\n",
        "\n",
        "    if user_id is None:\n",
        "        return jsonify({\"status\": \"error\", \"message\": \"user_id is required\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Analyze data\n",
        "        word_freq = analyze_user_prompts(user_id, df)\n",
        "        sorted_word_freq = word_freq.most_common()\n",
        "\n",
        "        # Generate word frequency plot\n",
        "        plot_buffer = plot_horizontal_word_frequencies(sorted_word_freq, top_n=x)\n",
        "\n",
        "        # Return the plot as PNG\n",
        "        return Response(plot_buffer, mimetype='image/png')\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"status\": \"error\", \"message\": str(e)}), 500\n",
        "\n",
        "# API route for generating word cloud (PNG)\n",
        "@app.route('/word_cloud', methods=['GET'])\n",
        "def word_cloud():\n",
        "    user_id = request.args.get('user_id', type=int)\n",
        "    x = request.args.get('x', default=20, type=int)\n",
        "\n",
        "    if user_id is None:\n",
        "        return jsonify({\"status\": \"error\", \"message\": \"user_id is required\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Analyze data\n",
        "        word_freq = analyze_user_prompts(user_id, df)\n",
        "        sorted_word_freq = word_freq.most_common()\n",
        "\n",
        "        # Generate word cloud\n",
        "        wordcloud_buffer = generate_word_cloud(sorted_word_freq[:x])\n",
        "\n",
        "        # Return the word cloud as PNG\n",
        "        return Response(wordcloud_buffer, mimetype='image/png')\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"status\": \"error\", \"message\": str(e)}), 500\n",
        "\n",
        "# Run Flask app and ngrok\n",
        "def run_flask():\n",
        "    app.run(port=5000)\n",
        "\n",
        "flask_thread = threading.Thread(target=run_flask)\n",
        "flask_thread.start()\n",
        "\n",
        "time.sleep(5)\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:5000\\\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNCSlLQ95CmJ",
        "outputId": "86bf581a-f433-41c5-d6b5-32a8ac7b2173"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"NgrokTunnel: \"https://0bc9-35-196-231-166.ngrok-free.app\" -> \"http://localhost:5000\"\" -> \"http://127.0.0.1:5000\"\n"
          ]
        }
      ]
    }
  ]
}